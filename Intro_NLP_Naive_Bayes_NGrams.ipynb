{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP: Traditional approaches\n",
    "\n",
    "# Naives Bayes and N-Grams for Text classification\n",
    "\n",
    "The purpose of this notebook is to cover Naive Bayes and ngrams (some pretty classic techniques!) for text classification. We will be using some popular libraries like sklearn but we will implement some operation \"manually\", not using an existing package for educational purpose. *I will review and follow part of the exceptional NLP course by Rachel Thomas in Fastai, and most lines of code has been extracted or adapted from its notebook 3* (the link is down there) and 3b.\n",
    "\n",
    "As in previous notebooks, this is a text classifier to identify fake tweets relatives to disasters. But we are not interested in the best model, we want to show you some traditional \"tools\" and methods to solve this kind of NLP problems and explain the concepts around them. \n",
    "\n",
    "Link to problem description in Kaggle: \n",
    "\n",
    "Link to code:\n",
    "- https://github.com/fastai/course-nlp/blob/master/3-logreg-nb-imdb.ipynb\n",
    "- https://github.com/lazyprogrammer/machine_learning_examples/blob/master/nlp_class/spam2.py\n",
    "\n",
    "Link to blog post or aditional readings:\n",
    "- https://sebastianraschka.com/Articles/2014_naive_bayes_1.html\n",
    "- https://web.stanford.edu/class/cs124/lec/naivebayes.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sn\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Just once\n",
    "#import nltk\n",
    "#nltk.download('wordnet')\n",
    "# Import the lemmatizer and the tokenizdr\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Import module to work with sparse matrixes\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the variables for data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters relatives to file location and names\n",
    "#root folder\n",
    "root_folder='.'\n",
    "#data_folder='.'\n",
    "data_folder_name='.'\n",
    "train_filename='train.csv'\n",
    "# Variable for data directory\n",
    "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "\n",
    "# Both train and test set are in the root data directory\n",
    "train_path = DATA_PATH\n",
    "test_path = DATA_PATH\n",
    "\n",
    "#Relevant columns\n",
    "TEXT_COLUMN = 'text'\n",
    "TARGET_COLUMN = 'target'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the datasets\n",
    "\n",
    "This notebook does not cover how to implement the best preprocessor to clean our tweets. So we are going to feed our model with the tweet as is or only removing no alphanumeric characters. For a better results, we should inspect the tweets and apply some cleaning removing useless words, mispelling words, maybe the URIs,... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the tweets of our train dataset\n",
    "data = pd.read_csv(train_path+'\\\\'+train_filename)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  Our Deeds are the Reason of this #earthquake M...       1\n",
       "1             Forest fire near La Ronge Sask. Canada       1\n",
       "2  All residents asked to 'shelter in place' are ...       1\n",
       "3  13,000 people receive #wildfires evacuation or...       1\n",
       "4  Just got sent this photo from Ruby #Alaska as ...       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extract only the text and target columns from our dataframe\n",
    "data = data[[TEXT_COLUMN, TARGET_COLUMN]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data to be used in our model\n",
    "\n",
    "This notebook does not cover how to implement the best preprocessor to clean our tweets. So we are going to feed our model with the tweet as is or only removing no alphanumeric characters.\n",
    "\n",
    "We split the train dataset into a train and validation dataset so we can evaluate the result and apply tricks like cross-validation. This job is done as in many others notebooks, using sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X Train Size: (6090,)\n",
      "X Test Size: (1523,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into a train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(data[TEXT_COLUMN], data[TARGET_COLUMN].values, \n",
    "                                                    test_size=0.20, random_state=0)\n",
    "\n",
    "print('X Train Size:',X_train.shape)\n",
    "print('X Test Size:',X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we show some tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ted Cruz fires back at Jeb &amp; Bush: ÛÏWe lose because of Republicans like Jeb &amp; Mitt.Û [Video] http://t.co/FgDEh56PLO\n",
      "This is the first year the Forest Service spent more than half its annual budget on fighting fires. #climatechange http://t.co/D62zfZy0Mi\n",
      "@lightseraphs pissed at you and could have their pikachu electrocute you and :\\\\\\\n",
      "I'm gonna fight Taylor as soon as I get there.\n",
      "@NicolaClements4 IÛªm not sure that covering my head in wounds and scabs is the solution ;)\n",
      "kabwandi_: Breaking news! Unconfirmed! I just heard a loud bang nearby. in what appears to be a blast of wind from my neighbour's ass.\n",
      "The annihilation of Jeb Christie &amp; Kasich is less than 24 hours away..\n",
      "Please God allow me at least one more full day...\n",
      "Wtf this mom just drowned her child?!\n",
      "@MayorofLondon pls reduce cyclist deaths with a compulsory highway code test as with EVERY OTHER VEHICLE that uses a road. #notrocketscience\n",
      "@DoctorDryadma mass murder here we come\n"
     ]
    }
   ],
   "source": [
    "for doc in X_train[:10]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the tokens from our text data\n",
    "\n",
    "- **What is lemmatizer?**\n",
    "For grammatical reasons, documents are going to use different forms of a word and there are families of derivationally related words with similar meanings, such as democracy, democratic, and democratization. In many situations, it seems as if it would be useful for a search for one of these words to return documents that contain another word in the set. So we can obtain a shorter vocabulary if we use the root \"meaning\" or word of these groups of word. Lemmatization and Stemming are two techniques to get the root word, but steemming is so crude and usually returns word with no meaning. Lemmatization is usually a better aproach.\n",
    "\n",
    "We are going to use a very shor list of **Stop Words**. Stop words are generally the most common words in a language and they do not provide useful information about the context so we can remove them.\n",
    "- **Use of stopwords**\n",
    "\n",
    "Now it is time to convert a collection of text documents (our tweets) to a matrix of token/word counts. f you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stopword list and create a Lemmatizer object\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "# Define the stop words extracted from a file with only 20-30 words to remove \n",
    "stopwords = set(w.rstrip() for w in open('NLP_short_stopwords.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our tokenizer is very simple, apply lowercase to the text, remove very short words, lematize the words and finally remove the stopwords. As we said, we are not coding an expert parser for tweets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tokenizer(s):\n",
    "    s = s.lower() # downcase\n",
    "    tokens = word_tokenize(s) # split string into words (tokens)\n",
    "    tokens = [t for t in tokens if len(t) > 2] # remove short words, they're probably not useful\n",
    "    tokens = [wordnet_lemmatizer.lemmatize(t) for t in tokens] # put words into base form\n",
    "    tokens = [t for t in tokens if t not in stopwords] # remove stopwords\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to tokens and create the vocabulary\n",
    "\n",
    "First we need to create our vocabulary, the list of words/tokens we are expecting in our sentences. We tokenize all the tweets, save all the tokens and include them (not repeted) in the vocabulary. Our vocabulary is based on the train set (it is supossed that the test set is just for testing our model we do not know anything about it). But there would be probably new \"tokens\" in our test set (or in a future test text) so we include a token for \"unknown\" words, every new word will be replaced by this token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary:  18434\n"
     ]
    }
   ],
   "source": [
    "#We need to create our vocabulary. We tokenize every document, collect the tokens and extract the vocabulary.\n",
    "all_tokens=[]\n",
    "tokens=set()\n",
    "for doc in X_train:\n",
    "    # Extract tokens in doc\n",
    "    doc_tokens=my_tokenizer(doc)\n",
    "    # Store the tokens in two lists\n",
    "    all_tokens.append(doc_tokens)\n",
    "    tokens.update(set(doc_tokens))\n",
    "\n",
    "# Create our dictionary or vocabulary to convert string/token to int\n",
    "vocab={k:v for v, k in enumerate(tokens)}\n",
    "# Add the token unknown to the dictionary\n",
    "vocab['xxUNKxx']=len(vocab)\n",
    "print('Vocabulary: ',len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the term document matrix of our train and test data\n",
    "\n",
    "Now we will create our own version of the Term Document Matrix. This is for two reasons:\n",
    "- to understand what sklearn is doing underneath the hood\n",
    "- to create something that will work with a fastai TextList\n",
    "\n",
    "To create our term-document matrix, we will use counters and sparse matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the term document matrix. We are not going to use any package, just pass through the text and build our matrix.\n",
    "def get_term_doc_matrix(documents,vocab):\n",
    "    ''' Create and return the Term Document Matriz based on the documents and words provided as arguments'''\n",
    "    j_indices = []\n",
    "    indptr = []\n",
    "    values = []\n",
    "    indptr.append(0)\n",
    "\n",
    "    for doc in documents:\n",
    "        tokenstoi = [vocab[t] for t in doc]\n",
    "        feature_counter = Counter(tokenstoi)\n",
    "        j_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        indptr.append(len(j_indices))\n",
    "    \n",
    "    \n",
    "     # for debugging purpose              \n",
    "    #return (values, j_indices, indptr)\n",
    "    return csr_matrix((values, j_indices, indptr),\n",
    "                                    shape=(len(indptr) - 1, len(vocab)),\n",
    "                                    dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the Text Document Matrix\n",
    "#v,j,i = get_term_doc_matrix(all_tokens,vocab)\n",
    "trn_term_doc  = get_term_doc_matrix(all_tokens,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6090, 18434)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the test dataset we need to check if the token is in the vocab, if not we replace it by the especial token for unknown words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens=[]\n",
    "\n",
    "for doc in X_test:\n",
    "    doc_tokens=my_tokenizer(doc)\n",
    "    all_tokens.append([t if t in vocab else 'xxUNKxx' for t in doc_tokens])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_term_doc  = get_term_doc_matrix(all_tokens,vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1523, 18434)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Naive Bayes classifiers, a family of classifiers that are based on the popular Bayes’ probability theorem, are known for creating simple yet well performing models, especially in the fields of document classification and disease prediction. The probabilistic model of naive Bayes classifiers is based on Bayes’ theorem, and the adjective naive comes from the assumption that the features in a dataset are mutually independent. In practice, the independence assumption is often violated, but naive Bayes classifiers still tend to perform very well under this unrealistic assumption [1]. Especially for small sample sizes, naive Bayes classifiers can outperform the more powerful alternatives.\n",
    "\n",
    "Bayes’ rule can be written down in simple words as follows:\n",
    "\n",
    "$posterior probability = \\frac{\\text{conditional probability}⋅\\text{prior probability}}{\\text{evidence}}$\n",
    "\n",
    "In the context of pattern classification, the prior probabilities are also called class priors, which describe “the general probability of encountering a particular class.” In our case , the priors could be formulated as\n",
    "\n",
    "$P(fake)=\"\\text{the probability that any new message is a fake message}\"$ and $P(real)=1−P(fake)$\n",
    "\n",
    "And in context of text classification:\n",
    "\n",
    "$P(fake) = \\frac{\\text{# of fake messages in training data}}{\\text{# of all messages in training data}}$\n",
    "\n",
    "For numerical stability purpose, we’re going to look at the log probability by taking the log of each side. Now we’re dealing with additions of log probabilities instead of multiplying many probabilities together! Since log has really nice properties (monotonicity being the key one), we can still take the highest score to be our prediction, i.e., we don’t have to “undo” the log!\n",
    "\n",
    "**Explain**\n",
    "\n",
    "We define the log-count ratio $r$ for each word $f$:\n",
    "\n",
    "$r = \\log \\frac{\\text{ratio of feature $f$ in positive documents}}{\\text{ratio of feature $f$ in negative documents}}$\n",
    "\n",
    "where ratio of feature $f$ in positive documents is the number of times a positive document has a feature divided by the number of positive documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x is the term document matrix\n",
    "x = trn_term_doc\n",
    "# y is the target label\n",
    "y = y_train\n",
    "val_y = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y_train==1].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y_train==0].sum(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2634, 18434)\n",
      "(3456, 18434)\n"
     ]
    }
   ],
   "source": [
    "print(x[y_train==1].shape)\n",
    "print(x[y_train==0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  0,  0,  0,  0,  0,  1,  0,  1,  2,  1,  0,  0,  1,  1,  0,  1,\n",
       "       16,  2,  1,  1,  2,  0,  0,  1,  0,  1,  1,  4,  1,  1,  1,  1,  0,\n",
       "        0,  0,  1, 11,  2,  2,  0,  1,  0,  0,  1,  0,  1,  1,  0,  0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to avoid the problem of zero probabilities or division by zero, an additional smoothing term can be added to the  Bayes model. The most common variants of additive smoothing are the so-called Lidstone smoothing (α<1) and Laplace smoothing (α=1). So, we add 1 to the numerator and denominator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr1 = (p1+1) / ((y_train==1).sum() + 1)\n",
    "pr0 = (p0+1) / ((y_train==0).sum() + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.88095589, -0.4216292 , -0.4216292 , ..., -0.90713702,\n",
       "        0.96466516,  0.27151798])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = np.log(pr1/pr0)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vocab most likely associated with positive/negative reviews**\n",
    "\n",
    "In the next cells we will observe the vocabulary in the most positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest = np.argpartition(r, -10)[-10:]\n",
    "smallest = np.argpartition(r, 10)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['derailment',\n",
       " 'investigator',\n",
       " 'debris',\n",
       " 'hiroshima',\n",
       " 'migrant',\n",
       " 'northern',\n",
       " 'legionnaire',\n",
       " 'mh370',\n",
       " 'severe',\n",
       " 'malaysia']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(vocab.keys())[list(vocab.values()).index(k)] for k in biggest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mayhem',\n",
       " 'bag',\n",
       " 'cat',\n",
       " 'career',\n",
       " 'ruin',\n",
       " 'disney',\n",
       " 'ebay',\n",
       " 'lmao',\n",
       " 'character',\n",
       " 'crushed']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[list(vocab.keys())[list(vocab.values()).index(k)] for k in smallest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Naives Bayes\n",
    "\n",
    "Now we can apply the \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.432512315270936, 0.5674876847290641)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_train==1).mean(), (y_train==0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.log((y_train==1).mean() / (y_train==0).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (val_term_doc @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7636244254760342"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:  [[650 236]\n",
      " [124 513]]\n",
      "Accuracy:  0.7636244254760342\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "#y_pred = model.predict(test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_auc_score,roc_curve,auc\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('Confusion Matrix: ',cm)\n",
    "# Calculate the accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy: ',acc)\n",
    "# Calculate the points in the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred, pos_label=1)\n",
    "roc_auc= auc(fpr,tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ed0cb5a390>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "# Create a dataframe with the confussion matrix values\n",
    "df_cm = pd.DataFrame(cm, range(cm.shape[0]),\n",
    "                  range(cm.shape[1]))\n",
    "# Plot the confussion matrix\n",
    "#plt.figure(figsize = (10,7))\n",
    "sn.set(font_scale=1.4) #for label size\n",
    "sn.heatmap(df_cm, annot=True,fmt='.0f',annot_kws={\"size\": 10})# font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve\n",
    "# plot no skill\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration: negative to positive ratios\n",
    "I was curious about the ratio of times a given word appears in negative reviews to times it occurs in positive reviews. Bigger ratios (> 1) mean the word is indicative of a negative review, and smaller ratios (< 1) mean it is indicative of a positive review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neg_pos_given_word(word):\n",
    "    print(p0[vocab[word]]/p1[vocab[word]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.75\n"
     ]
    }
   ],
   "source": [
    "neg_pos_given_word('real')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarized Naive Bayes\n",
    "Maybe it only matters whether a word is in the review or not (not the frequency of the word). So instead of the frequency of a token our term-document matrix will only contain 1 or 0 as values. This step simplifies the model and sometimes it can produce a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a term document matrix binarized, containing only 1 or 0 values if the word is in the text\n",
    "x=trn_term_doc.sign()\n",
    "y=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.todense()[:50,:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same steps as before but using the binarized term document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.squeeze(np.asarray(x[y_train==1].sum(0)))\n",
    "p0 = np.squeeze(np.asarray(x[y_train==0].sum(0)))\n",
    "\n",
    "pr1 = (p1+1) / ((y_train==1).sum() + 1)\n",
    "pr0 = (p0+1) / ((y_train==0).sum() + 1)\n",
    "\n",
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y_train==1).mean() / (y_train==0).mean())\n",
    "\n",
    "preds = (val_term_doc.sign() @ r + b) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7760998030203545"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds==val_y).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we get a very litle improvement, now we can use some other machine learning algos to help us to improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression\n",
    "Here is how we can fit logistic regression where the features are the **unigrams**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edumu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8076165462902167"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(x, y)\n",
    "preds = m.predict(val_term_doc)\n",
    "(preds==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got an accuracy of 80% using Logistic Regression on the unigrams of our Naives Bayes approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigrams with NB features\n",
    "Our next model is a version of logistic regression with Naive Bayes features described here. For every document we compute binarized features as described above, but this time we use bigrams and trigrams too. Each feature is a log-count ratio. A logistic regression model is then trained to predict if it is real or fake.\n",
    "\n",
    "### ngrams\n",
    "An n-gram is a contiguous sequence of n items (where the items can be characters, syllables, or words). A 1-gram is a unigram, a 2-gram is a bigram, and a 3-gram is a trigram.\n",
    "\n",
    "Here, we are referring to sequences of words. So examples of bigrams include \"the dog\", \"said that\", and \"can't you\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_n=1\n",
    "max_n=3\n",
    "\n",
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "num_tokens = len(vocab)\n",
    "\n",
    "itongram = dict()\n",
    "ngramtoi = dict()\n",
    "\n",
    "for doc in X_train:\n",
    "    doc_tokens=my_tokenizer(doc)\n",
    "    tokenstoi = [vocab[t] for t in doc_tokens]\n",
    "    feature_counter = Counter(tokenstoi)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(len(vocab) - n + 1):\n",
    "            ngram = tokenstoi[k: k + n]\n",
    "            if str(ngram) not in ngramtoi:\n",
    "                if len(ngram)==1:\n",
    "                    num = ngram[0]\n",
    "                    ngramtoi[str(ngram)] = num\n",
    "                    itongram[num] = ngram\n",
    "                else:\n",
    "                    ngramtoi[str(ngram)] = num_tokens\n",
    "                    itongram[num_tokens] = ngram\n",
    "                    num_tokens += 1\n",
    "            this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the trigrams document matrix\n",
    "train_ngram_doc_matrix = csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6090x118201 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 268987 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118201, 118201)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ngramtoi), len(itongram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17116, 2348]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'v' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-30e1ce99a663>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitongram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m25000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m189\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1301\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'v' is not defined"
     ]
    }
   ],
   "source": [
    "print(itongram[25000])\n",
    "print(v[189], v[1301]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create valid matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_indices = []\n",
    "indptr = []\n",
    "values = []\n",
    "indptr.append(0)\n",
    "\n",
    "for doc in X_test:\n",
    "    doc_tokens=my_tokenizer(doc)\n",
    "    doc_tokens = [t if t in vocab else 'xxUNKxx' for t in doc_tokens]\n",
    "    tokenstoi = [vocab[t] for t in doc_tokens]\n",
    "    feature_counter = Counter(tokenstoi)\n",
    "    j_indices.extend(feature_counter.keys())\n",
    "    values.extend(feature_counter.values())\n",
    "    this_doc_ngrams = list()\n",
    "\n",
    "    m = 0\n",
    "    for n in range(min_n, max_n + 1):\n",
    "        for k in range(len(vocab) - n + 1):\n",
    "            ngram = tokenstoi[k: k + n]\n",
    "            if str(ngram) in ngramtoi:\n",
    "                this_doc_ngrams.append(ngramtoi[str(ngram)])\n",
    "            m += 1\n",
    "\n",
    "    ngram_counter = Counter(this_doc_ngrams)\n",
    "    j_indices.extend(ngram_counter.keys())\n",
    "    values.extend(ngram_counter.values())\n",
    "    indptr.append(len(j_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ngram_doc_matrix = csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, len(ngramtoi)),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_ngram_doc_matrix\n",
    "y=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6090x118201 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 268987 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=118201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = (y == 1)[:k]\n",
    "neg = (y == 0)[:k]\n",
    "xx = x[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6090x118201 sparse matrix of type '<class 'numpy.int32'>'\n",
       "\twith 268987 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b:  -0.2716082476207199\n"
     ]
    }
   ],
   "source": [
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))\n",
    "\n",
    "pr1 = (p1+1) / ((y==1).sum() + 1)\n",
    "pr0 = (p0+1) / ((y==0).sum() + 1)\n",
    "\n",
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y==1).mean() / (y==0).mean())\n",
    "print('b: ',b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_preds = valid_ngram_doc_matrix @ r.T + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-28.36480922,  -9.17880064,   2.03173239, ...,  13.46042239,\n",
       "       -21.65151714,   9.0190975 ])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003939592908733"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = pre_preds.T>0\n",
    "(preds == y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the results are better, but not significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binarized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7734734077478661"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_x_ngram_sgn = train_ngram_doc_matrix.sign()\n",
    "val_x_ngram_sgn = valid_ngram_doc_matrix.sign()\n",
    "xx = trn_x_ngram_sgn[:k]\n",
    "\n",
    "p0 = np.squeeze(np.array(xx[neg].sum(0)))\n",
    "p1 = np.squeeze(np.array(xx[pos].sum(0)))\n",
    "pr1 = (p1+1) / ((y==1).sum() + 1)\n",
    "pr0 = (p0+1) / ((y==0).sum() + 1)\n",
    "r = np.log(pr1/pr0)\n",
    "b = np.log((y==1).mean() / (y==0).mean())\n",
    "\n",
    "pre_preds = val_x_ngram_sgn @ r.T + b\n",
    "preds = pre_preds.T>0\n",
    "\n",
    "(preds==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Here we fit logistic regression where the features are the trigrams.\n",
    "And we will use **CountVectorizer** to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "veczr = CountVectorizer(ngram_range=(1,3), max_features=800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [[t for t in my_tokenizer(doc)] for doc in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_words = [[t for t in my_tokenizer(doc)] for doc in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ted',\n",
       " 'cruz',\n",
       " 'fire',\n",
       " 'back',\n",
       " 'jeb',\n",
       " 'amp',\n",
       " 'bush',\n",
       " '\\x89ûïwe',\n",
       " 'lose',\n",
       " 'because',\n",
       " 'republican',\n",
       " 'like',\n",
       " 'jeb',\n",
       " 'amp',\n",
       " 'mitt.\\x89û\\x9d',\n",
       " 'video',\n",
       " 'http',\n",
       " '//t.co/fgdeh56plo']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_ngram_doc = veczr.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6090x142879 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 259286 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ted': 116371,\n",
       " 'cruz': 33940,\n",
       " 'fires': 46451,\n",
       " 'back': 14096,\n",
       " 'at': 12507,\n",
       " 'jeb': 70693,\n",
       " 'amp': 7482,\n",
       " 'bush': 20743,\n",
       " 'ûïwe': 142775,\n",
       " 'lose': 77321,\n",
       " 'because': 15857,\n",
       " 'of': 88700,\n",
       " 'republicans': 102545,\n",
       " 'like': 75620,\n",
       " 'mitt': 81904,\n",
       " 'video': 131769,\n",
       " 'http': 59462,\n",
       " 'co': 25931,\n",
       " 'fgdeh56plo': 45756,\n",
       " 'ted cruz': 116372,\n",
       " 'cruz fires': 33943,\n",
       " 'fires back': 46465,\n",
       " 'back at': 14110,\n",
       " 'at jeb': 12754,\n",
       " 'jeb amp': 70694,\n",
       " 'amp bush': 7549,\n",
       " 'bush ûïwe': 20766,\n",
       " 'ûïwe lose': 142776,\n",
       " 'lose because': 77322,\n",
       " 'because of': 15901,\n",
       " 'of republicans': 89853,\n",
       " 'republicans like': 102549,\n",
       " 'like jeb': 75771,\n",
       " 'amp mitt': 7733,\n",
       " 'mitt video': 81905,\n",
       " 'video http': 131795,\n",
       " 'http co': 59463,\n",
       " 'co fgdeh56plo': 27550,\n",
       " 'ted cruz fires': 116374,\n",
       " 'cruz fires back': 33944,\n",
       " 'fires back at': 46466,\n",
       " 'back at jeb': 14111,\n",
       " 'at jeb amp': 12755,\n",
       " 'jeb amp bush': 70695,\n",
       " 'amp bush ûïwe': 7551,\n",
       " 'bush ûïwe lose': 20767,\n",
       " 'ûïwe lose because': 142777,\n",
       " 'lose because of': 77323,\n",
       " 'because of republicans': 15906,\n",
       " 'of republicans like': 89854,\n",
       " 'republicans like jeb': 102550,\n",
       " 'like jeb amp': 75772,\n",
       " 'jeb amp mitt': 70696,\n",
       " 'amp mitt video': 7734,\n",
       " 'mitt video http': 81906,\n",
       " 'video http co': 131796,\n",
       " 'http co fgdeh56plo': 60610,\n",
       " 'this': 122652,\n",
       " 'is': 68068,\n",
       " 'the': 117893,\n",
       " 'first': 46576,\n",
       " 'year': 140050,\n",
       " 'forest': 48615,\n",
       " 'service': 107585,\n",
       " 'spent': 112095,\n",
       " 'more': 82508,\n",
       " 'than': 116971,\n",
       " 'half': 54358,\n",
       " 'its': 70049,\n",
       " 'annual': 10184,\n",
       " 'budget': 20161,\n",
       " 'on': 91271,\n",
       " 'fighting': 45877,\n",
       " 'climatechange': 25660,\n",
       " 'd62zfzy0mi': 34494,\n",
       " 'this is': 122865,\n",
       " 'is the': 68839,\n",
       " 'the first': 119008,\n",
       " 'first year': 46698,\n",
       " 'year the': 140113,\n",
       " 'the forest': 119055,\n",
       " 'forest service': 48655,\n",
       " 'service spent': 107623,\n",
       " 'spent more': 112100,\n",
       " 'more than': 82654,\n",
       " 'than half': 117038,\n",
       " 'half its': 54376,\n",
       " 'its annual': 70059,\n",
       " 'annual budget': 10187,\n",
       " 'budget on': 20166,\n",
       " 'on fighting': 91520,\n",
       " 'fighting fires': 45880,\n",
       " 'fires climatechange': 46475,\n",
       " 'climatechange http': 25663,\n",
       " 'co d62zfzy0mi': 27202,\n",
       " 'this is the': 122886,\n",
       " 'is the first': 68857,\n",
       " 'the first year': 119023,\n",
       " 'first year the': 46699,\n",
       " 'year the forest': 140114,\n",
       " 'the forest service': 119058,\n",
       " 'forest service spent': 48664,\n",
       " 'service spent more': 107624,\n",
       " 'spent more than': 112101,\n",
       " 'more than half': 82667,\n",
       " 'than half its': 117039,\n",
       " 'half its annual': 54377,\n",
       " 'its annual budget': 70060,\n",
       " 'annual budget on': 10188,\n",
       " 'budget on fighting': 20167,\n",
       " 'on fighting fires': 91521,\n",
       " 'fighting fires climatechange': 45881,\n",
       " 'fires climatechange http': 46476,\n",
       " 'climatechange http co': 25664,\n",
       " 'http co d62zfzy0mi': 60363,\n",
       " 'lightseraphs': 75614,\n",
       " 'pissed': 96608,\n",
       " 'you': 140500,\n",
       " 'and': 8282,\n",
       " 'could': 32780,\n",
       " 'have': 55290,\n",
       " 'their': 121345,\n",
       " 'pikachu': 96484,\n",
       " 'electrocute': 41268,\n",
       " 'lightseraphs pissed': 75615,\n",
       " 'pissed at': 96609,\n",
       " 'at you': 13024,\n",
       " 'you and': 140521,\n",
       " 'and could': 8545,\n",
       " 'could have': 32830,\n",
       " 'have their': 55645,\n",
       " 'their pikachu': 121440,\n",
       " 'pikachu electrocute': 96485,\n",
       " 'electrocute you': 41294,\n",
       " 'lightseraphs pissed at': 75616,\n",
       " 'pissed at you': 96610,\n",
       " 'at you and': 13025,\n",
       " 'you and could': 140523,\n",
       " 'and could have': 8546,\n",
       " 'could have their': 32833,\n",
       " 'have their pikachu': 55646,\n",
       " 'their pikachu electrocute': 121441,\n",
       " 'pikachu electrocute you': 96486,\n",
       " 'electrocute you and': 41295,\n",
       " 'gonna': 52328,\n",
       " 'fight': 45830,\n",
       " 'taylor': 116133,\n",
       " 'as': 11894,\n",
       " 'soon': 111526,\n",
       " 'get': 51032,\n",
       " 'there': 121772,\n",
       " 'gonna fight': 52356,\n",
       " 'fight taylor': 45853,\n",
       " 'taylor as': 116136,\n",
       " 'as soon': 12114,\n",
       " 'soon as': 111529,\n",
       " 'as get': 11978,\n",
       " 'get there': 51235,\n",
       " 'gonna fight taylor': 52357,\n",
       " 'fight taylor as': 45854,\n",
       " 'taylor as soon': 116137,\n",
       " 'as soon as': 12115,\n",
       " 'soon as get': 111530,\n",
       " 'as get there': 11979,\n",
       " 'nicolaclements4': 86344,\n",
       " 'ûªm': 142518,\n",
       " 'not': 87206,\n",
       " 'sure': 114920,\n",
       " 'that': 117176,\n",
       " 'covering': 33143,\n",
       " 'my': 83862,\n",
       " 'head': 56230,\n",
       " 'in': 64668,\n",
       " 'wounds': 139135,\n",
       " 'scabs': 106124,\n",
       " 'solution': 111094,\n",
       " 'nicolaclements4 ûªm': 86345,\n",
       " 'ûªm not': 142519,\n",
       " 'not sure': 87478,\n",
       " 'sure that': 114945,\n",
       " 'that covering': 117286,\n",
       " 'covering my': 33144,\n",
       " 'my head': 84245,\n",
       " 'head in': 56256,\n",
       " 'in wounds': 66428,\n",
       " 'wounds and': 139140,\n",
       " 'and scabs': 9450,\n",
       " 'scabs is': 106125,\n",
       " 'the solution': 120589,\n",
       " 'nicolaclements4 ûªm not': 86346,\n",
       " 'ûªm not sure': 142520,\n",
       " 'not sure that': 87480,\n",
       " 'sure that covering': 114946,\n",
       " 'that covering my': 117287,\n",
       " 'covering my head': 33145,\n",
       " 'my head in': 84249,\n",
       " 'head in wounds': 56259,\n",
       " 'in wounds and': 66429,\n",
       " 'wounds and scabs': 139143,\n",
       " 'and scabs is': 9451,\n",
       " 'scabs is the': 106126,\n",
       " 'is the solution': 68878,\n",
       " 'kabwandi_': 71994,\n",
       " 'breaking': 19521,\n",
       " 'news': 85992,\n",
       " 'unconfirmed': 129349,\n",
       " 'just': 71450,\n",
       " 'heard': 56421,\n",
       " 'loud': 77454,\n",
       " 'bang': 14607,\n",
       " 'nearby': 85348,\n",
       " 'what': 135281,\n",
       " 'appears': 10727,\n",
       " 'to': 124312,\n",
       " 'be': 15204,\n",
       " 'blast': 17790,\n",
       " 'wind': 137086,\n",
       " 'from': 49410,\n",
       " 'neighbour': 85549,\n",
       " 'ass': 12375,\n",
       " 'kabwandi_ breaking': 71995,\n",
       " 'breaking news': 19535,\n",
       " 'news unconfirmed': 86128,\n",
       " 'unconfirmed just': 129350,\n",
       " 'just heard': 71625,\n",
       " 'heard loud': 56432,\n",
       " 'loud bang': 77461,\n",
       " 'bang nearby': 14624,\n",
       " 'nearby in': 85351,\n",
       " 'in what': 66394,\n",
       " 'what appears': 135294,\n",
       " 'appears to': 10730,\n",
       " 'to be': 124459,\n",
       " 'be blast': 15259,\n",
       " 'blast of': 17799,\n",
       " 'of wind': 90424,\n",
       " 'wind from': 137102,\n",
       " 'from my': 49634,\n",
       " 'my neighbour': 84389,\n",
       " 'neighbour ass': 85550,\n",
       " 'kabwandi_ breaking news': 71996,\n",
       " 'breaking news unconfirmed': 19539,\n",
       " 'news unconfirmed just': 86129,\n",
       " 'unconfirmed just heard': 129351,\n",
       " 'just heard loud': 71626,\n",
       " 'heard loud bang': 56433,\n",
       " 'loud bang nearby': 77469,\n",
       " 'bang nearby in': 14625,\n",
       " 'nearby in what': 85352,\n",
       " 'in what appears': 66395,\n",
       " 'what appears to': 135295,\n",
       " 'appears to be': 10732,\n",
       " 'to be blast': 124465,\n",
       " 'be blast of': 15260,\n",
       " 'blast of wind': 17800,\n",
       " 'of wind from': 90425,\n",
       " 'wind from my': 137103,\n",
       " 'from my neighbour': 49639,\n",
       " 'my neighbour ass': 84390,\n",
       " 'annihilation': 10128,\n",
       " 'christie': 25052,\n",
       " 'kasich': 72147,\n",
       " 'less': 74983,\n",
       " '24': 1670,\n",
       " 'hours': 59065,\n",
       " 'away': 13832,\n",
       " 'please': 97122,\n",
       " 'god': 52042,\n",
       " 'allow': 6778,\n",
       " 'me': 79866,\n",
       " 'least': 74571,\n",
       " 'one': 92208,\n",
       " 'full': 50112,\n",
       " 'day': 35147,\n",
       " 'the annihilation': 118045,\n",
       " 'annihilation of': 10135,\n",
       " 'of jeb': 89472,\n",
       " 'jeb christie': 70699,\n",
       " 'christie amp': 25053,\n",
       " 'amp kasich': 7706,\n",
       " 'kasich is': 72148,\n",
       " 'is less': 68523,\n",
       " 'less than': 74997,\n",
       " 'than 24': 116978,\n",
       " '24 hours': 1680,\n",
       " 'hours away': 59069,\n",
       " 'away please': 13862,\n",
       " 'please god': 97153,\n",
       " 'god allow': 52043,\n",
       " 'allow me': 6783,\n",
       " 'me at': 79897,\n",
       " 'at least': 12759,\n",
       " 'least one': 74599,\n",
       " 'one more': 92312,\n",
       " 'more full': 82557,\n",
       " 'full day': 50124,\n",
       " 'the annihilation of': 118047,\n",
       " 'annihilation of jeb': 10138,\n",
       " 'of jeb christie': 89473,\n",
       " 'jeb christie amp': 70700,\n",
       " 'christie amp kasich': 25054,\n",
       " 'amp kasich is': 7707,\n",
       " 'kasich is less': 72149,\n",
       " 'is less than': 68524,\n",
       " 'less than 24': 74998,\n",
       " 'than 24 hours': 116979,\n",
       " '24 hours away': 1682,\n",
       " 'hours away please': 59072,\n",
       " 'away please god': 13863,\n",
       " 'please god allow': 97154,\n",
       " 'god allow me': 52044,\n",
       " 'allow me at': 6784,\n",
       " 'me at least': 79900,\n",
       " 'at least one': 12772,\n",
       " 'least one more': 74600,\n",
       " 'one more full': 92313,\n",
       " 'more full day': 82558,\n",
       " 'wtf': 139499,\n",
       " 'mom': 82223,\n",
       " 'drowned': 39875,\n",
       " 'her': 56962,\n",
       " 'child': 24747,\n",
       " 'wtf this': 139508,\n",
       " 'this mom': 122940,\n",
       " 'mom just': 82234,\n",
       " 'just drowned': 71558,\n",
       " 'drowned her': 39883,\n",
       " 'her child': 56988,\n",
       " 'wtf this mom': 139509,\n",
       " 'this mom just': 122941,\n",
       " 'mom just drowned': 82235,\n",
       " 'just drowned her': 71559,\n",
       " 'drowned her child': 39884,\n",
       " 'mayoroflondon': 79770,\n",
       " 'pls': 97228,\n",
       " 'reduce': 101779,\n",
       " 'cyclist': 34381,\n",
       " 'deaths': 35706,\n",
       " 'with': 137350,\n",
       " 'compulsory': 31893,\n",
       " 'highway': 57495,\n",
       " 'code': 30957,\n",
       " 'test': 116795,\n",
       " 'every': 43191,\n",
       " 'other': 93326,\n",
       " 'vehicle': 131299,\n",
       " 'uses': 130742,\n",
       " 'road': 103781,\n",
       " 'notrocketscience': 87661,\n",
       " 'mayoroflondon pls': 79771,\n",
       " 'pls reduce': 97235,\n",
       " 'reduce cyclist': 101782,\n",
       " 'cyclist deaths': 34382,\n",
       " 'deaths with': 35749,\n",
       " 'with compulsory': 137457,\n",
       " 'compulsory highway': 31894,\n",
       " 'highway code': 57498,\n",
       " 'code test': 30964,\n",
       " 'test as': 116802,\n",
       " 'as with': 12198,\n",
       " 'with every': 137506,\n",
       " 'every other': 43237,\n",
       " 'other vehicle': 93375,\n",
       " 'vehicle that': 131321,\n",
       " 'that uses': 117785,\n",
       " 'uses road': 130745,\n",
       " 'road notrocketscience': 103811,\n",
       " 'mayoroflondon pls reduce': 79772,\n",
       " 'pls reduce cyclist': 97236,\n",
       " 'reduce cyclist deaths': 101783,\n",
       " 'cyclist deaths with': 34383,\n",
       " 'deaths with compulsory': 35750,\n",
       " 'with compulsory highway': 137458,\n",
       " 'compulsory highway code': 31895,\n",
       " 'highway code test': 57499,\n",
       " 'code test as': 30965,\n",
       " 'test as with': 116803,\n",
       " 'as with every': 12199,\n",
       " 'with every other': 137507,\n",
       " 'every other vehicle': 43238,\n",
       " 'other vehicle that': 93377,\n",
       " 'vehicle that uses': 131322,\n",
       " 'that uses road': 117786,\n",
       " 'uses road notrocketscience': 130746,\n",
       " 'doctordryadma': 38494,\n",
       " 'mass': 79337,\n",
       " 'murder': 83543,\n",
       " 'here': 57123,\n",
       " 'we': 134117,\n",
       " 'come': 31458,\n",
       " 'doctordryadma mass': 38495,\n",
       " 'mass murder': 79349,\n",
       " 'murder here': 83565,\n",
       " 'here we': 57200,\n",
       " 'we come': 134165,\n",
       " 'doctordryadma mass murder': 38496,\n",
       " 'mass murder here': 79358,\n",
       " 'murder here we': 83566,\n",
       " 'here we come': 57201,\n",
       " 'weapon_x_music': 134505,\n",
       " 'hey': 57285,\n",
       " 'guys': 53870,\n",
       " 'thanks': 117140,\n",
       " 'for': 47630,\n",
       " 'rock': 103947,\n",
       " 'world': 138658,\n",
       " 'follow': 47453,\n",
       " 'weapon_x_music hey': 134506,\n",
       " 'hey guys': 57292,\n",
       " 'guys thanks': 53891,\n",
       " 'thanks for': 117149,\n",
       " 'for rock': 48216,\n",
       " 'rock in': 103958,\n",
       " 'in my': 65630,\n",
       " 'my world': 84616,\n",
       " 'world and': 138661,\n",
       " 'and for': 8772,\n",
       " 'for the': 48324,\n",
       " 'the follow': 119048,\n",
       " 'weapon_x_music hey guys': 134507,\n",
       " 'hey guys thanks': 57293,\n",
       " 'guys thanks for': 53892,\n",
       " 'thanks for rock': 117151,\n",
       " 'for rock in': 48217,\n",
       " 'rock in my': 103959,\n",
       " 'in my world': 65658,\n",
       " 'my world and': 84617,\n",
       " 'world and for': 138662,\n",
       " 'and for the': 8774,\n",
       " 'for the follow': 48351,\n",
       " 'hurricane': 63396,\n",
       " 'mixxtail': 81940,\n",
       " 'kinda': 72822,\n",
       " 'tastes': 116072,\n",
       " 'watermelon': 133842,\n",
       " 'four': 48901,\n",
       " 'loko': 76858,\n",
       " 'brittsand9': 19821,\n",
       " 'the hurricane': 119328,\n",
       " 'hurricane mixxtail': 63422,\n",
       " 'mixxtail kinda': 81941,\n",
       " 'kinda tastes': 72837,\n",
       " 'tastes like': 116073,\n",
       " 'like the': 75896,\n",
       " 'the watermelon': 121033,\n",
       " 'watermelon four': 133843,\n",
       " 'four loko': 48914,\n",
       " 'loko brittsand9': 76859,\n",
       " 'the hurricane mixxtail': 119329,\n",
       " 'hurricane mixxtail kinda': 63423,\n",
       " 'mixxtail kinda tastes': 81942,\n",
       " 'kinda tastes like': 72838,\n",
       " 'tastes like the': 116075,\n",
       " 'like the watermelon': 75906,\n",
       " 'the watermelon four': 121034,\n",
       " 'watermelon four loko': 133844,\n",
       " 'four loko brittsand9': 48915,\n",
       " 'apollo': 10674,\n",
       " 'brown': 19998,\n",
       " 'ûò': 142786,\n",
       " 'detonate': 37017,\n",
       " 'ft': 49895,\n",
       " 'åêm': 142381,\n",
       " 'jd7rik7fx0': 70664,\n",
       " 'h6ngsw9a5b': 53979,\n",
       " 'apollo brown': 10675,\n",
       " 'brown ûò': 20024,\n",
       " 'ûò detonate': 142802,\n",
       " 'detonate ft': 37031,\n",
       " 'ft åêm': 49906,\n",
       " 'åêm http': 142382,\n",
       " 'co jd7rik7fx0': 28213,\n",
       " 'jd7rik7fx0 http': 70665,\n",
       " 'co h6ngsw9a5b': 27836,\n",
       " 'apollo brown ûò': 10679,\n",
       " 'brown ûò detonate': 20025,\n",
       " 'ûò detonate ft': 142803,\n",
       " 'detonate ft åêm': 37034,\n",
       " 'ft åêm http': 49907,\n",
       " 'åêm http co': 142383,\n",
       " 'http co jd7rik7fx0': 61066,\n",
       " 'co jd7rik7fx0 http': 28214,\n",
       " 'jd7rik7fx0 http co': 70666,\n",
       " 'http co h6ngsw9a5b': 60806,\n",
       " 'usa': 130584,\n",
       " 'chemical': 24606,\n",
       " 'spill': 112128,\n",
       " 'evacuations': 42942,\n",
       " 'red': 101654,\n",
       " 'cross': 33742,\n",
       " 'emergency': 41520,\n",
       " '007npen6lg': 48,\n",
       " 'usa breaking': 130589,\n",
       " 'news chemical': 86021,\n",
       " 'chemical spill': 24635,\n",
       " 'spill evacuations': 112141,\n",
       " 'evacuations red': 42947,\n",
       " 'red cross': 101667,\n",
       " 'cross emergency': 33761,\n",
       " 'emergency http': 41579,\n",
       " 'co 007npen6lg': 25932,\n",
       " 'usa breaking news': 130590,\n",
       " 'breaking news chemical': 19537,\n",
       " 'news chemical spill': 86022,\n",
       " 'chemical spill evacuations': 24638,\n",
       " 'spill evacuations red': 112142,\n",
       " 'evacuations red cross': 42948,\n",
       " 'red cross emergency': 101668,\n",
       " 'cross emergency http': 33762,\n",
       " 'emergency http co': 41580,\n",
       " 'http co 007npen6lg': 59464,\n",
       " 'kushwush': 73462,\n",
       " 'still': 113239,\n",
       " 'traumatised': 127589,\n",
       " 'by': 21272,\n",
       " 'your': 141400,\n",
       " 'driving': 39696,\n",
       " 'having': 55742,\n",
       " 'flashbacks': 46932,\n",
       " 'lane': 73907,\n",
       " 'hogging': 58289,\n",
       " 'kushwush still': 73463,\n",
       " 'still traumatised': 113374,\n",
       " 'traumatised by': 127600,\n",
       " 'by your': 21752,\n",
       " 'your driving': 141485,\n",
       " 'driving having': 39708,\n",
       " 'having flashbacks': 55757,\n",
       " 'flashbacks of': 46935,\n",
       " 'of the': 90065,\n",
       " 'the lane': 119483,\n",
       " 'lane hogging': 73910,\n",
       " 'kushwush still traumatised': 73464,\n",
       " 'still traumatised by': 113375,\n",
       " 'traumatised by your': 127603,\n",
       " 'by your driving': 21753,\n",
       " 'your driving having': 141486,\n",
       " 'driving having flashbacks': 39709,\n",
       " 'having flashbacks of': 55758,\n",
       " 'flashbacks of the': 46936,\n",
       " 'of the lane': 90145,\n",
       " 'the lane hogging': 119484,\n",
       " 'alcoholandmetal': 6309,\n",
       " 'do': 38299,\n",
       " 'anything': 10515,\n",
       " 'fix': 46768,\n",
       " 'few': 45702,\n",
       " 'people': 95562,\n",
       " 'he': 55937,\n",
       " 'had': 54030,\n",
       " 'trusted': 128220,\n",
       " 'his': 57885,\n",
       " 'life': 75337,\n",
       " 'charles': 24415,\n",
       " 'was': 133083,\n",
       " 'casualties': 23440,\n",
       " 'alcoholandmetal do': 6310,\n",
       " 'do anything': 38311,\n",
       " 'anything to': 10536,\n",
       " 'to fix': 124961,\n",
       " 'fix that': 46773,\n",
       " 'that of': 117584,\n",
       " 'the few': 118973,\n",
       " 'few people': 45721,\n",
       " 'people he': 95634,\n",
       " 'he had': 56050,\n",
       " 'had every': 54066,\n",
       " 'every trusted': 43260,\n",
       " 'trusted in': 128221,\n",
       " 'in his': 65351,\n",
       " 'his life': 57987,\n",
       " 'life charles': 75356,\n",
       " 'charles was': 24419,\n",
       " 'was one': 133385,\n",
       " 'one of': 92322,\n",
       " 'the casualties': 118409,\n",
       " 'alcoholandmetal do anything': 6311,\n",
       " 'do anything to': 38314,\n",
       " 'anything to fix': 10537,\n",
       " 'to fix that': 124962,\n",
       " 'fix that of': 46774,\n",
       " 'that of the': 117585,\n",
       " 'of the few': 90125,\n",
       " 'the few people': 118974,\n",
       " 'few people he': 45722,\n",
       " 'people he had': 95635,\n",
       " 'he had every': 56052,\n",
       " 'had every trusted': 54067,\n",
       " 'every trusted in': 43261,\n",
       " 'trusted in his': 128222,\n",
       " 'in his life': 65357,\n",
       " 'his life charles': 57989,\n",
       " 'life charles was': 75357,\n",
       " 'charles was one': 24420,\n",
       " 'was one of': 133386,\n",
       " 'one of the': 92329,\n",
       " 'of the casualties': 90093,\n",
       " 'xbox': 139678,\n",
       " '360': 2182,\n",
       " 'pro': 98779,\n",
       " 'console': 32237,\n",
       " 'ring': 103446,\n",
       " 'death': 35622,\n",
       " 'read': 101088,\n",
       " 'ebay': 40796,\n",
       " '5gktshiorr': 2887,\n",
       " '9jeuu86koi': 3780,\n",
       " 'xbox 360': 139679,\n",
       " '360 pro': 2185,\n",
       " 'pro console': 98782,\n",
       " 'console red': 32240,\n",
       " 'red ring': 101703,\n",
       " 'ring of': 103451,\n",
       " 'of death': 89071,\n",
       " 'death full': 35647,\n",
       " 'full read': 50142,\n",
       " 'read by': 101097,\n",
       " 'by ebay': 21384,\n",
       " 'ebay http': 40803,\n",
       " 'co 5gktshiorr': 26368,\n",
       " '5gktshiorr http': 2888,\n",
       " 'co 9jeuu86koi': 26696,\n",
       " 'xbox 360 pro': 139681,\n",
       " '360 pro console': 2186,\n",
       " 'pro console red': 98783,\n",
       " 'console red ring': 32241,\n",
       " 'red ring of': 101704,\n",
       " 'ring of death': 103452,\n",
       " 'of death full': 89072,\n",
       " 'death full read': 35648,\n",
       " 'full read by': 50143,\n",
       " 'read by ebay': 101098,\n",
       " 'by ebay http': 21385,\n",
       " 'ebay http co': 40804,\n",
       " 'http co 5gktshiorr': 59762,\n",
       " 'co 5gktshiorr http': 26369,\n",
       " '5gktshiorr http co': 2889,\n",
       " 'http co 9jeuu86koi': 59995,\n",
       " 'obama': 88426,\n",
       " 'declares': 35882,\n",
       " 'disaster': 37765,\n",
       " 'typhoon': 128973,\n",
       " 'devastated': 37090,\n",
       " 'saipan': 105331,\n",
       " 'signs': 109164,\n",
       " 'declaration': 35871,\n",
       " 'northern': 87139,\n",
       " 'marians': 79122,\n",
       " 'vts9cayibc': 132354,\n",
       " 'obama declares': 88435,\n",
       " 'declares disaster': 35885,\n",
       " 'disaster for': 37797,\n",
       " 'for typhoon': 48432,\n",
       " 'typhoon devastated': 128974,\n",
       " 'devastated saipan': 37106,\n",
       " 'saipan obama': 105334,\n",
       " 'obama signs': 88455,\n",
       " 'signs disaster': 109167,\n",
       " 'disaster declaration': 37789,\n",
       " 'declaration for': 35872,\n",
       " 'for northern': 48110,\n",
       " 'northern marians': 87154,\n",
       " 'marians http': 79123,\n",
       " 'co vts9cayibc': 30223,\n",
       " 'obama declares disaster': 88436,\n",
       " 'declares disaster for': 35886,\n",
       " 'disaster for typhoon': 37799,\n",
       " 'for typhoon devastated': 48433,\n",
       " 'typhoon devastated saipan': 128975,\n",
       " 'devastated saipan obama': 37108,\n",
       " 'saipan obama signs': 105335,\n",
       " 'obama signs disaster': 88456,\n",
       " 'signs disaster declaration': 109169,\n",
       " 'disaster declaration for': 37790,\n",
       " 'declaration for northern': 35874,\n",
       " 'for northern marians': 48113,\n",
       " 'northern marians http': 87155,\n",
       " 'marians http co': 79124,\n",
       " 'http co vts9cayibc': 62436,\n",
       " 'will': 136764,\n",
       " 'held': 56682,\n",
       " 'hostage': 58890,\n",
       " 'radical': 100276,\n",
       " 'group': 53395,\n",
       " 'you will': 141307,\n",
       " 'will be': 136777,\n",
       " 'be held': 15393,\n",
       " 'held hostage': 56686,\n",
       " 'hostage by': 58899,\n",
       " 'by radical': 21604,\n",
       " 'radical group': 100277,\n",
       " 'you will be': 141308,\n",
       " 'will be held': 136799,\n",
       " 'be held hostage': 15394,\n",
       " 'held hostage by': 56687,\n",
       " 'hostage by radical': 58901,\n",
       " 'by radical group': 21605,\n",
       " 'choking': 24949,\n",
       " 'hazard': 55807,\n",
       " 'prompts': 99039,\n",
       " 'recall': 101480,\n",
       " 'kraft': 73370,\n",
       " 'cheese': 24572,\n",
       " 'singles': 109401,\n",
       " 'xgkyvf9t4f': 139723,\n",
       " 'choking hazard': 24950,\n",
       " 'hazard prompts': 55841,\n",
       " 'prompts recall': 99040,\n",
       " 'recall of': 101483,\n",
       " 'of kraft': 89499,\n",
       " 'kraft cheese': 73371,\n",
       " 'cheese singles': 24579,\n",
       " 'singles http': 109402,\n",
       " 'co xgkyvf9t4f': 30457,\n",
       " 'choking hazard prompts': 24953,\n",
       " 'hazard prompts recall': 55842,\n",
       " 'prompts recall of': 99041,\n",
       " 'recall of kraft': 101484,\n",
       " 'of kraft cheese': 89500,\n",
       " 'kraft cheese singles': 73372,\n",
       " 'cheese singles http': 24580,\n",
       " 'singles http co': 109403,\n",
       " 'http co xgkyvf9t4f': 62595,\n",
       " 'fav': 45148,\n",
       " 'worlds': 138784,\n",
       " 'collided': 31251,\n",
       " 'lennonparham': 74928,\n",
       " 'jessica_stclair': 70768,\n",
       " 'found': 48853,\n",
       " 'gilmoreguysshow': 51546,\n",
       " 'podcast': 97363,\n",
       " 'ihave44episodesofgg': 64237,\n",
       " 'nojoke': 86991,\n",
       " 'my fav': 84130,\n",
       " 'fav worlds': 45151,\n",
       " 'worlds have': 138788,\n",
       " 'have collided': 55384,\n",
       " 'collided thanks': 31280,\n",
       " 'thanks to': 117167,\n",
       " 'to lennonparham': 125254,\n",
       " 'lennonparham jessica_stclair': 74929,\n",
       " 'jessica_stclair found': 70769,\n",
       " 'found the': 48882,\n",
       " 'the gilmoreguysshow': 119143,\n",
       " 'gilmoreguysshow podcast': 51547,\n",
       " 'podcast ihave44episodesofgg': 97364,\n",
       " 'ihave44episodesofgg nojoke': 64238,\n",
       " 'my fav worlds': 84132,\n",
       " 'fav worlds have': 45152,\n",
       " 'worlds have collided': 138789,\n",
       " 'have collided thanks': 55386,\n",
       " 'collided thanks to': 31281,\n",
       " 'thanks to lennonparham': 117170,\n",
       " 'to lennonparham jessica_stclair': 125255,\n",
       " 'lennonparham jessica_stclair found': 74930,\n",
       " 'jessica_stclair found the': 70770,\n",
       " 'found the gilmoreguysshow': 48883,\n",
       " 'the gilmoreguysshow podcast': 119144,\n",
       " 'gilmoreguysshow podcast ihave44episodesofgg': 51548,\n",
       " 'podcast ihave44episodesofgg nojoke': 97365,\n",
       " 'going': 52164,\n",
       " 'hollywood': 58375,\n",
       " 'abc7eyewitness': 4077,\n",
       " 'abc7': 4071,\n",
       " 'helicopters': 56717,\n",
       " 'sirens': 109596,\n",
       " 'hometownglory': 58552,\n",
       " 'what going': 135349,\n",
       " 'going on': 52195,\n",
       " 'on in': 91645,\n",
       " 'in hollywood': 65366,\n",
       " 'hollywood abc7eyewitness': 58376,\n",
       " 'abc7eyewitness abc7': 4078,\n",
       " 'abc7 helicopters': 4072,\n",
       " 'helicopters and': 56718,\n",
       " 'and sirens': 9512,\n",
       " 'sirens hometownglory': 109606,\n",
       " 'what going on': 135350,\n",
       " 'going on in': 52200,\n",
       " 'on in hollywood': 91646,\n",
       " 'in hollywood abc7eyewitness': 65367,\n",
       " 'hollywood abc7eyewitness abc7': 58377,\n",
       " 'abc7eyewitness abc7 helicopters': 4079,\n",
       " 'abc7 helicopters and': 4073,\n",
       " 'helicopters and sirens': 56719,\n",
       " 'and sirens hometownglory': 9513,\n",
       " 'such': 114367,\n",
       " 'activities': 4885,\n",
       " 'govt': 52867,\n",
       " 'can': 22458,\n",
       " 'derail': 36531,\n",
       " 'us': 130421,\n",
       " 'our': 93448,\n",
       " 'aim': 5963,\n",
       " 'remain': 102134,\n",
       " 'peaceful': 95443,\n",
       " 'unite': 129559,\n",
       " 'freesikhpoliticalprisnors': 49237,\n",
       " 'bapusuratsingh': 14700,\n",
       " 'such activities': 114368,\n",
       " 'activities of': 4888,\n",
       " 'of govt': 89276,\n",
       " 'govt can': 52874,\n",
       " 'can derail': 22518,\n",
       " 'derail us': 36563,\n",
       " 'us from': 130483,\n",
       " 'from our': 49669,\n",
       " 'our aim': 93451,\n",
       " 'aim amp': 5964,\n",
       " 'amp we': 7911,\n",
       " 'we still': 134345,\n",
       " 'still remain': 113338,\n",
       " 'remain peaceful': 102141,\n",
       " 'peaceful and': 95446,\n",
       " 'and unite': 9795,\n",
       " 'unite for': 129560,\n",
       " 'for freesikhpoliticalprisnors': 47906,\n",
       " 'freesikhpoliticalprisnors amp': 49238,\n",
       " 'amp bapusuratsingh': 7528,\n",
       " 'such activities of': 114369,\n",
       " 'activities of govt': 4889,\n",
       " 'of govt can': 89278,\n",
       " 'govt can derail': 52875,\n",
       " 'can derail us': 22519,\n",
       " 'derail us from': 36564,\n",
       " 'us from our': 130484,\n",
       " 'from our aim': 49670,\n",
       " 'our aim amp': 93452,\n",
       " 'aim amp we': 5965,\n",
       " 'amp we still': 7912,\n",
       " 'we still remain': 134350,\n",
       " 'still remain peaceful': 113339,\n",
       " 'remain peaceful and': 102142,\n",
       " 'peaceful and unite': 95447,\n",
       " 'and unite for': 9796,\n",
       " 'unite for freesikhpoliticalprisnors': 129561,\n",
       " 'for freesikhpoliticalprisnors amp': 47907,\n",
       " 'freesikhpoliticalprisnors amp bapusuratsingh': 49239,\n",
       " 'so': 110565,\n",
       " 'cool': 32496,\n",
       " 'garbanzobean23': 50637,\n",
       " 'cutest': 34299,\n",
       " 'indot': 66768,\n",
       " 'worker': 138594,\n",
       " 'but': 20820,\n",
       " 'might': 81218,\n",
       " 'little': 76341,\n",
       " 'bias': 17143,\n",
       " 'g7k9tqvqbk': 50400,\n",
       " 'so cool': 110615,\n",
       " 'cool garbanzobean23': 32500,\n",
       " 'garbanzobean23 in': 50638,\n",
       " 'in the': 66070,\n",
       " 'the news': 119881,\n",
       " 'news cutest': 86028,\n",
       " 'cutest indot': 34300,\n",
       " 'indot worker': 66769,\n",
       " 'worker but': 138595,\n",
       " 'but might': 21000,\n",
       " 'might be': 81223,\n",
       " 'be little': 15439,\n",
       " 'little bias': 76342,\n",
       " 'bias http': 17144,\n",
       " 'co g7k9tqvqbk': 27656,\n",
       " 'so cool garbanzobean23': 110616,\n",
       " 'cool garbanzobean23 in': 32501,\n",
       " 'garbanzobean23 in the': 50639,\n",
       " 'in the news': 66166,\n",
       " 'the news cutest': 119882,\n",
       " 'news cutest indot': 86029,\n",
       " 'cutest indot worker': 34301,\n",
       " 'indot worker but': 66770,\n",
       " 'worker but might': 138596,\n",
       " 'but might be': 21001,\n",
       " 'might be little': 81226,\n",
       " 'be little bias': 15440,\n",
       " 'little bias http': 76343,\n",
       " 'bias http co': 17145,\n",
       " 'http co g7k9tqvqbk': 60684,\n",
       " 'latestnews': 74236,\n",
       " 'tension': 116600,\n",
       " 'bayelsa': 15074,\n",
       " 'patience': 95204,\n",
       " 'jonathan': 71144,\n",
       " 'plans': 96914,\n",
       " 'hijack': 57510,\n",
       " 'apc': 10610,\n",
       " 'pdp': 95400,\n",
       " 'latestnews tension': 74241,\n",
       " 'tension in': 116601,\n",
       " 'in bayelsa': 64870,\n",
       " 'bayelsa as': 15075,\n",
       " 'as patience': 12076,\n",
       " 'patience jonathan': 95207,\n",
       " 'jonathan plans': 71149,\n",
       " 'plans to': 96933,\n",
       " 'to hijack': 125128,\n",
       " 'hijack apc': 57511,\n",
       " 'apc pdp': 10616,\n",
       " 'latestnews tension in': 74242,\n",
       " 'tension in bayelsa': 116603,\n",
       " 'in bayelsa as': 64871,\n",
       " 'bayelsa as patience': 15076,\n",
       " 'as patience jonathan': 12077,\n",
       " 'patience jonathan plans': 95209,\n",
       " 'jonathan plans to': 71150,\n",
       " 'plans to hijack': 96935,\n",
       " 'to hijack apc': 125129,\n",
       " 'hijack apc pdp': 57513,\n",
       " 'kmactwn': 73019,\n",
       " 'meaganerd': 80223,\n",
       " 'looks': 77176,\n",
       " 'bowl': 19250,\n",
       " 'weather': 134584,\n",
       " 'cereal': 24054,\n",
       " 'new': 85729,\n",
       " 'kellogg': 72322,\n",
       " 'sugar': 114470,\n",
       " 'hail': 54220,\n",
       " 'stays': 113041,\n",
       " 'crunchy': 33849,\n",
       " 'even': 42972,\n",
       " 'milk': 81414,\n",
       " 'kmactwn meaganerd': 73020,\n",
       " 'meaganerd looks': 80224,\n",
       " 'looks like': 77191,\n",
       " 'like bowl': 75657,\n",
       " 'bowl of': 19253,\n",
       " 'of weather': 90379,\n",
       " 'weather cereal': 134598,\n",
       " 'cereal new': 24055,\n",
       " 'new kellogg': 85837,\n",
       " 'kellogg sugar': 72323,\n",
       " 'sugar hail': 114471,\n",
       " 'hail stays': 54257,\n",
       " 'stays crunchy': 113042,\n",
       " 'crunchy even': 33850,\n",
       " 'even in': 43003,\n",
       " 'in milk': 65586,\n",
       " 'kmactwn meaganerd looks': 73021,\n",
       " 'meaganerd looks like': 80225,\n",
       " 'looks like bowl': 77192,\n",
       " 'like bowl of': 75658,\n",
       " 'bowl of weather': 19255,\n",
       " 'of weather cereal': 90380,\n",
       " 'weather cereal new': 134599,\n",
       " 'cereal new kellogg': 24056,\n",
       " 'new kellogg sugar': 85838,\n",
       " 'kellogg sugar hail': 72324,\n",
       " 'sugar hail stays': 114472,\n",
       " 'hail stays crunchy': 54258,\n",
       " 'stays crunchy even': 113043,\n",
       " 'crunchy even in': 33851,\n",
       " 'even in milk': 43004,\n",
       " 'record': 101585,\n",
       " 'drought': 39774,\n",
       " 'united': 129563,\n",
       " 'states': 112942,\n",
       " 'hasn': 55199,\n",
       " 'been': 16065,\n",
       " 'hit': 58119,\n",
       " 'major': 78420,\n",
       " 'past': 95125,\n",
       " 'nine': 86518,\n",
       " 'years': 140124,\n",
       " 'it': 69274,\n",
       " 'seems': 107097,\n",
       " 'û_': 142388,\n",
       " 'in record': 65854,\n",
       " 'record hurricane': 101592,\n",
       " 'hurricane drought': 63407,\n",
       " 'drought the': 39807,\n",
       " 'the united': 120940,\n",
       " 'united states': 129574,\n",
       " 'states hasn': 112947,\n",
       " 'hasn been': 55200,\n",
       " 'been hit': 16162,\n",
       " 'hit by': 58130,\n",
       " 'by major': 21525,\n",
       " 'major hurricane': 78436,\n",
       " 'hurricane in': 63417,\n",
       " 'the past': 120062,\n",
       " 'past nine': 95139,\n",
       " 'nine years': 86527,\n",
       " 'years and': 140145,\n",
       " 'and it': 8993,\n",
       " 'it seems': 69773,\n",
       " 'seems like': 107102,\n",
       " 'like that': 75887,\n",
       " 'that û_': 117861,\n",
       " 'in record hurricane': 65855,\n",
       " 'record hurricane drought': 101593,\n",
       " 'hurricane drought the': 63409,\n",
       " 'drought the united': 39808,\n",
       " 'the united states': 120942,\n",
       " 'united states hasn': 129577,\n",
       " 'states hasn been': 112948,\n",
       " 'hasn been hit': 55201,\n",
       " 'been hit by': 16163,\n",
       " 'hit by major': 58135,\n",
       " ...}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "veczr.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ngram_doc = veczr.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = veczr.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['angry after odeon',\n",
       " 'angry and',\n",
       " 'angry and critical',\n",
       " 'angry god',\n",
       " 'angry god who',\n",
       " 'angry http',\n",
       " 'angry http co',\n",
       " 'angry internally',\n",
       " 'angry internally displaced',\n",
       " 'angry mad']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc[10000:10010]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using ngrams from CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edumu\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8003939592908733"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc, y_train);\n",
    "\n",
    "preds = m.predict(val_ngram_doc)\n",
    "(preds.T==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Binarized Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7977675640183848"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(C=0.1, dual=True)\n",
    "m.fit(train_ngram_doc.sign(), y_train);\n",
    "\n",
    "preds = m.predict(val_ngram_doc.sign())\n",
    "(preds.T==y_test).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression using my ngrams "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edumu\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.0001, class_weight=None, dual=True, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=50000,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m2 = LogisticRegression(C=0.0001, dual=True, max_iter=50000)\n",
    "m2.fit(train_ngram_doc_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41825344714379514"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = m2.predict(valid_ngram_doc_matrix)\n",
    "(preds.T==y_test).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
